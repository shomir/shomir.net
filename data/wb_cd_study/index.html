<html>
<head>
<title>Determiner-Established Deixis to Communicative Artifacts in Pedagogical Text</title>
<!--Google Analytics code begins below-->
<script type="text/javascript">

  var _gaq = _gaq || [];
  _gaq.push(['_setAccount', 'UA-36635929-1']);
  _gaq.push(['_trackPageview']);

  (function() {
    var ga = document.createElement('script'); ga.type = 'text/javascript'; ga.async = true;
    ga.src = ('https:' == document.location.protocol ? 'https://ssl' : 'http://www') + '.google-analytics.com/ga.js';
    var s = document.getElementsByTagName('script')[0]; s.parentNode.insertBefore(ga, s);
  })();

</script>
<!--Google Analytics code ends above-->
</head>
<body>
<h1>Determiner-Established Deixis to Communicative Artifacts in Pedagogical Text</h1>
<p>This page contains links and documentation for the datasets mentioned in the <a href="../swilson_acl_2014.pdf">paper</a>.</p>
<h2>Word Senses</h2>
<p><a href="raw_sense_annotations.csv">Here</a> is a CSV file containing the raw annotations from both annotators. Each row represents a unique synset/gloss, and the columns contain the following:
<ul>
<li>Column 1: label ascribed by annotator #1 ('y' for communicative artifacts; else 'n')</li>
<li>Column 2: label ascribed by annotator #2 (same marking scheme)</li>
<li>Column 3: word from candidate phrases in the text that brought the synset into consideration</li>
<li>Column 4: synset name</li>
<li>Column 5: synset gloss</li>
</ul>
The 200 rows in the above file represent the VCS set described in the paper.</p>

<p><a href="final_sense_annotations.csv">Here</a> is a CSV file containing the final annotations, with disagreements resolved. Each row represents a unique synset/gloss, and the columns contain the following:
<ul>
<li>Column 1: label ('y' for communicative artifacts; else 'n')</li>
<li>Column 2: word from candidate phrases in the text that brought the synset into consideration</li>
<li>Column 3: synset name</li>
<li>Column 4: synset gloss</li>
</ul>
The 62 'y' rows in the above file represent the CCS set described in the paper.</p>

<h2>Candidate Instances</h2>

<p><a href="candidate_instances.zip">Here</a> is a zip file containing CSV files for each of the 122 Wikibooks included in the paper analysis. Each row represents a match for the sought dependency patterns (i.e., a candidate instance of communicative deixis), and the columns represent the following:
<ul>
<li>Column 1: sentence number in the text (useful only if you wish to parse the entire document)</li>
<li>Column 2: one-indexed word position in the sentence of the start of the candidate instance</li>
<li>Column 3: one-indexed word position in the sentence of the end of the candidate instance</li>
<li>Column 4: determiner in the candidate instance</li>
<li>Column 5: noun in the candidate instance</li>
<li>Column 6: plain text of the sentence containing the candidate instance</li>
<li>Column 7: phrase-structure parse of the sentence containing the candidate instance (however, dependency parsing was instead used to identify candidate instances)</li>
</ul>
</p>

<h2>Wikibooks</h2>
<p> Finally, <a href=wikibooks_html_md.zip>here</a> is a zip file containing the HTML files for Wikibooks in the paper analysis, along with the <a href="https://daringfireball.net/projects/markdown/">markdown</a> files generated from them. Due to their size, CoreNLP results on the Wikibooks are available by request. Generating them may be a faster option.</p>

<hr/>
<p>Read more about me or find my contact information <a href="../index.html">here</a>.

</body>
</html>
