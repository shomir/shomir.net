<html>
<head>
<title>Determiner-Established Deixis to Communicative Artifacts in Pedagogical Text</title>
<!-- Google Analytics with modifications for GDPR: no cookies and no IP address collection -->
<!-- Some inspiration borrowed from https://helgeklein.com/blog/2020/06/google-analytics-cookieless-tracking-without-gdpr-consent/ -->
<script>
window.ga=window.ga||function(){(ga.q=ga.q||[]).push(arguments)};ga.l=+new Date;
ga('create', 'UA-36635929-1', {
  'storage': 'none', 'anonymize_ip': true
});

ga('send', 'pageview');
</script>
<script async src='https://www.google-analytics.com/analytics.js'></script>
<!-- End Google Analytics -->

</head>
<body>
<h1>Determiner-Established Deixis to Communicative Artifacts in Pedagogical Text</h1>
<p>This page contains links and documentation for the datasets mentioned in the <a href="../swilson_acl_2014.pdf">paper</a>.</p>
<h2>Word Senses</h2>
<p><a href="raw_sense_annotations.csv">Here</a> is a CSV file containing the raw annotations from both annotators. Each row represents a unique synset/gloss, and the columns contain the following:
<ul>
<li>Column 1: label ascribed by annotator #1 ('y' for communicative artifacts; else 'n')</li>
<li>Column 2: label ascribed by annotator #2 (same marking scheme)</li>
<li>Column 3: word from candidate phrases in the text that brought the synset into consideration</li>
<li>Column 4: synset name</li>
<li>Column 5: synset gloss</li>
</ul>
The 200 rows in the above file represent the VCS set described in the paper.</p>

<p><a href="final_sense_annotations.csv">Here</a> is a CSV file containing the final annotations, with disagreements resolved. Each row represents a unique synset/gloss, and the columns contain the following:
<ul>
<li>Column 1: label ('y' for communicative artifacts; else 'n')</li>
<li>Column 2: word from candidate phrases in the text that brought the synset into consideration</li>
<li>Column 3: synset name</li>
<li>Column 4: synset gloss</li>
</ul>
The 62 'y' rows in the above file represent the CCS set described in the paper.</p>

<h2>Candidate Instances</h2>

<p><a href="candidate_instances.zip">Here</a> is a zip file containing CSV files for each of the 122 Wikibooks included in the paper analysis. Each row represents a match for the sought dependency patterns (i.e., a candidate instance of communicative deixis), and the columns represent the following:
<ul>
<li>Column 1: sentence number in the text (useful only if you wish to parse the entire document)</li>
<li>Column 2: one-indexed word position in the sentence of the start of the candidate instance</li>
<li>Column 3: one-indexed word position in the sentence of the end of the candidate instance</li>
<li>Column 4: determiner in the candidate instance</li>
<li>Column 5: noun in the candidate instance</li>
<li>Column 6: plain text of the sentence containing the candidate instance</li>
<li>Column 7: phrase-structure parse of the sentence containing the candidate instance (however, dependency parsing was instead used to identify candidate instances)</li>
</ul>
</p>

<h2>Wikibooks</h2>
<p> Finally, <a href=wikibooks_html_md.zip>here</a> is a zip file containing the HTML files for Wikibooks in the paper analysis, along with the <a href="https://daringfireball.net/projects/markdown/">markdown</a> files generated from them. Due to their size, CoreNLP results on the Wikibooks are available by request. Generating them may be a faster option.</p>

<hr/>
<p>Read more about me or find my contact information <a href="../index.html">here</a>.

</body>
</html>
